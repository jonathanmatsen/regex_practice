import pandas as pd
import re

hn = pd.read_csv("hacker_news.csv")
titles = hn['title']

pattern = r"sql"

sql_counts = titles.str.contains(pattern, flags=re.I).sum()

# capture groups

import numpy as np

hn_sql = hn[hn['title'].str.contains(r"\w+SQL", flags=re.I)].copy()

pattern = r"(\w+SQL)"

hn_sql['flavor'] = hn_sql['title'].str.extract(pattern, flags = re.I)

hn_sql['flavor'] = hn_sql['flavor'].str.lower()

sql_pivot = hn_sql.pivot_table(index='flavor', values='num_comments', aggfunc=np.mean)

#using capture groups to extract data

pattern = r"[Pp]ython ([\d\.]+)"

py_versions = titles.str.extract(pattern).value_counts()

py_versions_freq = dict(py_versions)

#coounting mentions

def first_10_matches(pattern):
    """
    Return the first 10 story titles that match
    the provided regular expression
    """
    all_matches = titles[titles.str.contains(pattern)]
    first_10 = all_matches.head(10)
    return first_10

pattern = r"\b[Cc]\b[^.+]"

first_ten = first_10_matches(pattern)

#using lookarounds to control matches based on surrounding text
pattern = r"(?<!Series\s)\b[Cc]\b(?![\+\.])"

c_mentions = titles.str.contains(pattern).sum()

#backreferences: using capture groups in a regex pattern
pattern = r"\b(\w+)\s\1\b"

repeated_words = titles[titles.str.contains(pattern)]

#substituting regular expression matches
email_variations = pd.Series(['email', 'Email', 'e Mail',
                        'e mail', 'E-mail', 'e-mail',
                        'eMail', 'E-Mail', 'EMAIL'])

pattern = r"e[\-\s]?mail"

email_uniform = email_variations.str.replace(pattern, 'email', flags=re.I)

titles_clean = titles.str.replace(pattern, 'email', flags=re.I)
