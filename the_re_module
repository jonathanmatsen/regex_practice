#search for mentions within hacker news dataset

import re

titles = hn["title"].tolist()

python_mentions = 0

pattern = "[Pp]ython"

for title in titles:
    if re.search(pattern, title):
        python_mentions += 1

#use vectorized method to accomplish above

pattern = '[Pp]ython'

titles = hn['title']

python_mentions = titles.str.contains(pattern).sum()

# exploring continued
titles = hn['title']
ruby_titles = titles[titles.str.contains(r"[Rr]uby")]

#quanitfiers

email_bool = titles.str.contains(r"e-?mail")

email_count = email_bool.sum()

email_titles = titles[email_bool]

#character classes

pattern = "\[\w+\]"

tag_titles = titles.str.contains(pattern)

tag_count = tag_titles.sum()

# access the matching text with capture groups

pattern = r"\[(\w+)\]"

tags = titles.str.extract(pattern)

tag_freq = tags.value_counts()

# negative character classes

pattern = r"[Jj]ava[^sS]"

def first_10_matches(pattern):
    """
    Return the first 10 story titles that match
    the provided regular expression
    """
    all_matches = titles[titles.str.contains(pattern)]
    first_10 = all_matches.head(10)
    return first_10

java_titles = titles[titles.str.contains(pattern)]

# same as above but with word boundary
pattern = r"\b[Jj]ava\b"

java_titles = titles[titles.str.contains(pattern)]

# matching at the start and end of strings
beginning_count = titles.str.contains("^\[\w+\]").sum()

ending_count = titles.str.contains(r"\[\w+\]$").sum()
