#search for mentions within hacker news dataset

import re

titles = hn["title"].tolist()

python_mentions = 0

pattern = "[Pp]ython"

for title in titles:
    if re.search(pattern, title):
        python_mentions += 1

#use vectorized method to accomplish above

pattern = '[Pp]ython'

titles = hn['title']

python_mentions = titles.str.contains(pattern).sum()

# exploring continued
titles = hn['title']
ruby_titles = titles[titles.str.contains(r"[Rr]uby")]

#quanitfiers

email_bool = titles.str.contains(r"e-?mail")

email_count = email_bool.sum()

email_titles = titles[email_bool]

#character classes

pattern = "\[\w+\]"

tag_titles = titles.str.contains(pattern)

tag_count = tag_titles.sum()

# access the matching text with capture groups

pattern = r"\[(\w+)\]"

tags = titles.str.extract(pattern)

tag_freq = tags.value_counts()

# negative character classes

pattern = r"[Jj]ava[^sS]"

def first_10_matches(pattern):
    """
    Return the first 10 story titles that match
    the provided regular expression
    """
    all_matches = titles[titles.str.contains(pattern)]
    first_10 = all_matches.head(10)
    return first_10

java_titles = titles[titles.str.contains(pattern)]

# same as above but with word boundary
pattern = r"\b[Jj]ava\b"

java_titles = titles[titles.str.contains(pattern)]

# matching at the start and end of strings
beginning_count = titles.str.contains("^\[\w+\]").sum()

ending_count = titles.str.contains(r"\[\w+\]$").sum()

#using flags to modify regex patterns

import re

email_tests = pd.Series(['email', 'Email', 'e Mail', 'e mail', 'E-mail',
              'e-mail', 'eMail', 'E-Mail', 'EMAIL', 'emails', 'Emails',
              'E-Mails'])

pattern = r"\be[\-\s]?mails?\b"

email_mentions = titles.str.contains(pattern, flags=re.I).sum()

#extracting domains from URLs

test_urls = pd.Series([
 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',
 'http://www.interactivedynamicvideo.com/',
 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',
 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',
 'HTTPS://github.com/keppel/pinn',
 'Http://phys.org/news/2015-09-scale-solar-youve.html',
 'https://iot.seeed.cc',
 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',
 'http://beta.crowdfireapp.com/?beta=agnipath',
 'https://www.valid.ly?param',
 'http://css-cursor.techstream.org'
])

pattern = r"https?://([\w\-\.]+)"

test_urls_clean = test_urls.str.extract(pattern, flags=re.I)

domains = hn['url'].str.extract(pattern, flags=re.I)

top_domains = domains.value_counts().head()

#extracting URL parts using multiple capture groups

# `test_urls` is available from the previous screen

pattern = r"(https?)://([\w\-\.]+)/?(.*)"

test_url_parts = test_urls.str.extract(pattern, flags=re.I)

url_parts = hn['url'].str.extract(pattern, flags=re.I)

# using named capture groups to extract data
pattern = r"(?P<protocol>https?)://(?P<domain>[\w\.\-]+)/?(?P<path>.*)"

url_parts = hn['url'].str.extract(pattern, flags=re.I)
